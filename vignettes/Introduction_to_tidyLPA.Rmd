---
title: "Introduction to tidyLPA"
author: "Joshua M. Rosenberg"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to tidyLPA}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = T
)
```

# Background

`tidyLPA` provides an interface to the powerful MCLUST package to easily carry out Latent Profile Analysis (LPA). Its main contribution is corresponding that are commonly specified when carrying out LPA. Its secondary contribution is to make it easier to use the output in subsequent analysis through a tidy user interface, in that output is in the form of a `tibble` (closely related to a `data.frame`) that can subsequently be computed on.

The goal of `tidyLPA` is to provide tools to make it easier to use the `R` package [MCLUST](http://www.stat.washington.edu/mclust/) for Latent Profile Analysis analyses.

# Benchmark

`tidyLPA` has been benchmarked to MPlus, at least for a simple dataset (the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)) and with three of the more common model specifications. You can find the results of that benchmarking, which showed the results to be nearly identical, [here](https://jrosen48.github.io/blog/comparing-mplus-and-mclust-output/). 

# Example

Here is a very short example using the built-in dataset `pisaUSA15`:

```{r}
library(tidyLPA)
library(dplyr, warn.conflicts = FALSE)
m3 <- create_profiles_lpa(pisaUSA15, broad_interest, enjoyment, self_efficacy, n_profiles = 3, model = 2)
plot_profiles_lpa(m3)
```

```{r, echo = F, eval = F}
# this is for testing in-development versions
devtools::load_all(".")
```

# In-depth examples

Here are more in-depth examples. 

### A data-first, tidy approach

`tidyLPA` is presently designed to be used in two ways:

1. In a "data-first" (or tidy) way, akin to the interface popularized in the `dplyr` and `tidyr` (and other) packages - this approach is termed a "[tidy](https://www.tidyverse.org/)" approach in large parts of the R users community

1. In a more conventional, object-oriented way - this approach will be familiar to those who have used functions such as the built-in `lm()` function for general linear models (i.e., regression and ANOVA)

This example makes use of the first, data-first, tidy approach, in which a `data.frame` (or a `tibble` to those who use packages such as `dplyr` and other "tidy" packages) is both input and output by the main function in this package.

Using the built-in `pisaUSA15` dataset (using just 200 observations for illustrative purposes) and variables for broad interest, enjoyment, and self-efficacy, we can explore a three profile solution, with, for example, `4` profiles, and varying means across profiles, but equal variances and covariances (specified with model = `2`, which happens to be the default model if none is specified). More information the models described later in this vignette. Note that the number of profiles are typically chosen on the basis of evidence from multiple sources, including information criteria, statistical tests, and concerns of interpretability and parsimony. 

```{r, fig.width = 7, fig.height = 5}
library(tidyLPA)
library(dplyr, warn.conflicts = FALSE)
d <- pisaUSA15
d <- sample_n(pisaUSA15, 500)
create_profiles_lpa(d, broad_interest, enjoyment, self_efficacy, n_profiles = 4, model = 2)
```

**Note that if you get the warning "Some profiles are associated with no assignments. Interpret this solution with caution and consider other models", then this is a sign that a simpler model (with fewer profiles) likely fits better.

You can see the output is simply the same `tibble` that is input as the first function to `create_profiles_LPA`, but modified so that the classification and posterior probability of the classification are added (and incomplete cases with respect to the variables used to estimate the profiles removed).

We can then plot this output using the `plot_profiles_lpa()` function and the pipe (`%>%`) from the `dplyr` package:

```{r}
create_profiles_lpa(d, broad_interest, enjoyment, self_efficacy, n_profiles = 4, model = 2) %>% 
    plot_profiles_lpa()
```

Below is identical to the two lines of code above, except that instead of using the pipe, we save the output the object `m3`, and then call the `plot_profiles_lpa()` function on the output that it points to.

```{r, warning = F}
m3 <- create_profiles_lpa(d, broad_interest, enjoyment, self_efficacy, n_profiles = 4, model = 2)
plot_profiles_lpa(m3, to_center = TRUE)
```

We can also return the entire data frame. This returns a `tibble` with all of the variables in the original data, in this case `d`, so that subsequent analyses using variables that are not used to create the profile can be easily carried out.

```{r}
create_profiles_lpa(d, broad_interest, enjoyment, self_efficacy, n_profiles = 4, model = 2, return_orig_df = T) %>% 
    plot_profiles_lpa()
```

### An object-oriented approach

In addition to being used as part of a "tidy" approach, there is also an option to use it as part of a more conventional, object-oriented approach. In this example, instead of outputting a `tibble`, we will output an object of class  `Mclust`.

```{r}
m3_mclust <- create_profiles_lpa(d, broad_interest, enjoyment, self_efficacy, n_profiles = 4, model = 2, to_return = "mclust")
```

Any of the functions from the [MCLUST package](http://www.stat.washington.edu/mclust/) that work with this type of output will work on this output; the only difference is that the model is specified in this package (with the `create_profiles_lpa()` function) instead of the `Mclust()` function from the `MCLUST package`. 

In addition, a number of helper functions are available for extracting various model information.

```{r}
extract_mclust_summary(m3_mclust)
extract_variance(m3_mclust)
extract_covariance(m3_mclust)
```

# Models

As mentioned earlier, there are a number of different models representing different covariance matrix parameterizations that can be fit using `tidyLPA`. These are passed to the `model` argument to the `create_profiles_lpa()` function, i.e. `create_profiles_lpa(d, broad_interest, enjoyment, self_efficacy, n_profiles = 3, model = 2, to_return="tibble")`.

In general, the approach to choosing the model is similar to choosing the number of profiles, requiring deciding on the basis of evidence from multiple sources, including information criteria, statistical tests, and concerns of interpretability and parsimony. 

Here is more information on their specification, drawing from [Pastor's (2007)](http://www.sciencedirect.com/science/article/pii/S0361476X06000543) article. 

A few notes: 

* *p* represents different profiles (or mixture components).

* each covariance parameterization is represented by a 4 x 4 covariance matrix and therefore would represent the parameterization for a four-profile solution. 

**A. Varying means, equal variances, covariances fixed to 0 (model 1)**

*corresponds to the MCLUST model "EEI", "diagonal, equal volume and shape"*

$$
\left[ \begin{matrix} { \sigma  }_{ 1 }^{ 2 } & 0 & 0 & 0 \\ 0 & { \sigma  }_{ 2 }^{ 2 } & 0 & 0 \\ 0 & 0 & { \sigma  }_{ 3 }^{ 2 } & 0 \\ 0 & 0 & 0 & { \sigma  }_{ 4 }^{ 2 } \end{matrix} \right] 
$$

**B. Varying means, equal variances and covariances (model 2)**

*corresponds to the MCLUST model "EEE", "ellipsoidal, equal volume, shape, and orientation"*

$$
\left[ \begin{matrix} { \sigma  }_{ 1 }^{ 2 } & { \sigma  }_{ 21 } & { \sigma  }_{ 31 } & { \sigma  }_{ 41 } \\ { \sigma  }_{ 12 } & { \sigma  }_{ 2 }^{ 2 } & { \sigma  }_{ 23 } & { \sigma  }_{ 24 } \\ { \sigma  }_{ 13 } & { \sigma  }_{ 12 } & { \sigma  }_{ 3 }^{ 2 } & { \sigma  }_{ 33 } \\ { \sigma  }_{ 14 } & { \sigma  }_{ 12 } & { \sigma  }_{ 12 } & { \sigma  }_{ 4 }^{ 2 } \end{matrix} \right] 
$$

**C. Varying means and variances, covariances fixed to 0 (model 3)**

*corresponds to the MCLUST model "VVI", "diagonal, varying volume and shape"*

$$ 
\left[ \begin{matrix} { \sigma  }_{ 1p }^{ 2 } & 0 & 0 & 0 \\ 0 & { \sigma  }_{ 2p }^{ 2 } & 0 & 0 \\ 0 & 0 & { \sigma  }_{ 3p }^{ 2 } & 0 \\ 0 & 0 & 0 & { \sigma  }_{ 4p }^{ 2 } \end{matrix} \right] 
$$

**D. Varying means and variances, equal covariances (model 4)**

*This model cannot currently be specified in MCLUST*

$$
\left[ \begin{matrix} { \sigma  }_{ 1p }^{ 2 } & { \sigma  }_{ 21 } & { \sigma  }_{ 31 } & { \sigma  }_{ 41 } \\ { \sigma  }_{ 12 } & { \sigma  }_{ 2p }^{ 2 } & { \sigma  }_{ 23 } & { \sigma  }_{ 24 } \\ { \sigma  }_{ 13 } & { \sigma  }_{ 12 } & { \sigma  }_{ 3p }^{ 2 } & { \sigma  }_{ 33 } \\ { \sigma  }_{ 14 } & { \sigma  }_{ 12 } & { \sigma  }_{ 12 } & { \sigma  }_{ 4p }^{ 2 } \end{matrix} \right] 
$$

**E. Varying means, variances, and covariances**

*corresponds to the MCLUST model "VVV", "ellipsoidal, varying volume, shape, and orientation"*

$$
\left[ \begin{matrix} { \sigma  }_{ 1p }^{ 2 } & { \sigma  }_{ 21p } & { \sigma  }_{ 31p } & { \sigma  }_{ 41p } \\ { \sigma  }_{ 12p } & { \sigma  }_{ 2p }^{ 2 } & { \sigma  }_{ 23p } & { \sigma  }_{ 24p } \\ { \sigma  }_{ 13p } & { \sigma  }_{ 12p } & { \sigma  }_{ 3p }^{ 2 } & { \sigma  }_{ 33p } \\ { \sigma  }_{ 14p } & { \sigma  }_{ 12p } & { \sigma  }_{ 12p } & { \sigma  }_{ 4p }^{ 2 } \end{matrix} \right] 
$$

# Comparing many models using information criteria

We can quickly explore a number of models - both in terms of **the specification of the model** and **the number of profiles** using the Bayesian Information Criteria (BIC) values or the Integrated Completed Likelihood (ICL). For illustration, the built-in (to R) iris dataset is used a number of the models using the PISA data do not reach convergence.

```{r}
compare_models_lpa(iris, Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, statistic = "BIC")
compare_models_lpa(iris, Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, statistic = "ICL")
```

# Carrying out a bootstrapped likelihood-ratio test to choose the number of profiles for a specific model

To determine the number of profies for a specified model (i.e., models `1`-`3` described above, we can carry out a bootstrapped likelihood-ratio test. Note that the code is shown but run because it can take substantial time, even for a small dataset. 

```{r, eval = F}
bootstrap_lrt(d, broad_interest, enjoyment, self_efficacy, model = 3)
```

# Notes

* This is a sister-project to [prcr](https://github.com/jrosen48/prcr), for two-step cluster analysis. 

* [Pastor (2007)](http://www.sciencedirect.com/science/article/pii/S0361476X06000543) provides an accessible introduction to LPA, with an applied example in educational research. 

* To contribute, file issues via GitHub [here](https://github.com/jrosen48/tidyLPA/issues) or get in touch [via email or Twitter](https://jrosen48.github.io/about/).
