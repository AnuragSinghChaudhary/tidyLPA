<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to tidyLPA • tidyLPA</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to tidyLPA">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tidyLPA</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.4</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Introduction_to_tidyLPA.html">Introduction to tidyLPA</a>
    </li>
    <li>
      <a href="../articles/brief-overview.html">Brief overview of tidyLPA</a>
    </li>
    <li>
      <a href="../articles/introduction-to-major-changes.html">Forthcoming major changes</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Introduction to tidyLPA</h1>
                        <h4 class="author">Joshua M. Rosenberg</h4>
            
            <h4 class="date">2018-09-16</h4>
      
      
      <div class="hidden name"><code>Introduction_to_tidyLPA.Rmd</code></div>

    </div>

    
    
<p>Latent Profile Analysis (LPA) is a statistical modeling approach for estimating distinct profiles, or groups, of variables. In the social sciences and in educational research, these profiles could represent, for example, how different youth experience dimensions of being engaged (i.e., cognitively, behaviorally, and affectively) at the same time.</p>
<p>tidyLPA provides the functionality to carry out LPA in R. In particular, tidyLPA provides functionality to specify different models that determine whether and how different parameters (i.e., means, variances, and covariances) are estimated and to specify (and compare solutions for) the number of profiles to estimate.</p>
<p>This introduction to tidyLPA vignette is an overview of LPA and the tidyLPA package. This vignette covers the following topics:</p>
<ol style="list-style-type: decimal">
<li>Background on Latent Profile Analysis</li>
<li>Description of the goals of tidyLPA</li>
<li>Software approach to carrying out LPA: Interface to mclust (and to MPlus)</li>
<li>An example</li>
<li>More information on model specification</li>
<li>Other options</li>
<li>An interface to MPlus (in-development)</li>
<li>Other features</li>
<li>Conclusion</li>
</ol>
<div id="background-on-latent-profile-analysis-lpa" class="section level2">
<h2 class="hasAnchor">
<a href="#background-on-latent-profile-analysis-lpa" class="anchor"></a>1. Background on Latent Profile Analysis (LPA)</h2>
<p>Latent Profile Analysis (LPA) is a statistical modeling approach for estimating distinct profiles of variables. In the social sciences and in educational research, these profiles could represent, for example, how different youth experience dimensions of being engaged (i.e., cognitively, behaviorally, and affectively) at the same time. Note that LPA works best with continuous variables (and, in some cases, ordinal variables), but is not appropriate for dichotomous (binary) variables.</p>
<p>Many analysts have carried out LPA using a latent variable modeling approach. From this approach, different parameters - means, variances, and covariances - are freely estimated across profiles, fixed to be the same across profiles, or constrained to be zero. The MPlus software is commonly used to estimate these models (see <a href="https://www.statmodel.com/examples/mixture.shtml">here</a>) using the expectation-maximization (EM) algorithm to obtain the maximum likelihood estimates for the parameters.</p>
<p>Different <em>models</em> (or how or whether parameters are estimated) can be specified and estimated. While MPlus is widely-used (and powerful), it is costly, closed-source, and can be difficult to use, particularly with respect to interpreting or using the output of specified models as part of a reproducible workflow.</p>
</div>
<div id="description-of-the-goals-of-tidylpa" class="section level2">
<h2 class="hasAnchor">
<a href="#description-of-the-goals-of-tidylpa" class="anchor"></a>2. Description of the goals of tidyLPA</h2>
<p>The goal of tidyLPA is to make it easy to carry out LPA using R. In particular, tidyLPA provides an interface to the powerful and widely-used <a href="https://www.stat.washington.edu/mclust/">mclust</a> package for Gaussian Mixture Modeling. This means that tidyLPA does not contain code to carry out LPA directly, but rather provides “wrappers” to mclust functions that make them easier to use. The primary contributions of tidyLPA are to:</p>
<ol style="list-style-type: decimal">
<li>Provide functionality to specify models that are common to LPA</li>
<li>Make it easier to use the output in subsequent analysis through a <a href="https://CRAN.R-project.org/package=tidyverse/vignettes/manifesto.html">“tidy” interface</a>, in that:
<ul>
<li>input and output are both a <code>data.frame</code> (specifically its modified version, a <code>tibble</code>) that can be used to create plots or can be used in subsequent analyses</li>
<li>uses the “pipe” operator, <code>%&gt;%</code> to compose functions</li>
<li>being designed and documented to be easy to use, especially for beginners (but also to provide options for finer-grained choices for estimating the model and for viewing more specific forms of the LPA output)</li>
</ul>
</li>
</ol>
</div>
<div id="software-approach-to-carrying-out-lpa-interface-to-mclust-and-to-mplus" class="section level2">
<h2 class="hasAnchor">
<a href="#software-approach-to-carrying-out-lpa-interface-to-mclust-and-to-mplus" class="anchor"></a>3. Software approach to carrying out LPA: Interface to mclust (and to MPlus)</h2>
<p>In the open-source R software, there is not yet a tool to easily carry out LPA, though there are many tools that one could use to. For example, the <a href="https://openmx.ssri.psu.edu/">R version of OpenMx</a> can be used for this purpose (and to specify almost any model possible to specify within a latent variable modeling approach). However, while OpenMx is very flexible, it can also be challenging to use.</p>
<p>Other tools in R allow for estimating Gaussian mixture models, or models of multivariate Gaussian (or normal) distributions. In this framework, the term “mixture component” has a similar meaning to a profile. While much more constraining than the latent variable modeling framework, the approach is often similar or the same: the EM algorithm is used to (aim to) obtain the maximum likelihood estimates for the parameters being estimated. Like in the latent variable modeling framework, different models can be specified.</p>
<p>In addition to following the same general approach, using tools that are designed for Gaussian mixture modeling have other benefits, some efficiency-related (see <a href="https://cran.r-project.org/package=Rmixmod">RMixMod</a>, which uses compiled C++ code) and others in terms of ease-of-use (i.e., the plot methods built-in to RMixMod, mclust, and other tools). However, they also have some drawbacks, in that it can be difficult to translate between the model specifications, which are often described in terms of the geometric properties of the multivariate distributions being estimated (i.e., “spherical, equal volume”), rather than in terms of whether and how the means, variances, and covariances are estimated. They also may use different default settings (than those encountered in MPlus) in terms of the expectation-maximization algorithm, which can make comparing results across tools challenging.</p>
<p>This package focuses on models that are commonly specified as part of LPA. Because MPlus is so widely-used, it can be helpful to compare output from other software to MPlus. The functions in tidyLPA that use mclust have been benchmarked to MPlus for a series of simple models (with small datasets and for models with small numbers of profiles. This <a href="https://jrosen48.github.io/r-markdown/comparing-mplus-mclust.html">R Markdown output</a> contains information on how mclust and Mplus compare. The R Markdown to generate the output is also available <a href="https://jrosen48.github.io/r-markdown/comparing-mplus-mclust.Rmd">here</a>, and, as long as you have purchased MPlus (and installed MplusAutomation), can be used to replicate all of the results for the benchmark. Note that most of the output is identical, thoughthere are some differences in the hundreths decimal places for some. Because of differences in settings for the EM algorithm and particularly for the start values (random starts for MPlus and starting values from hierarchical clustering for mclust), differences may be expected for more complex data and models. An important direction for the development of tidyLPA (the functions that use mclust) is to continue to understand when and why the output differs from MPlus output. Note that tidyLPA also provides functions to interface to MPlus, though these are not the focus of the package, as they require MPlus to be purchased and installed in order to be used.</p>
</div>
<div id="an-example-using-mclust" class="section level2">
<h2 class="hasAnchor">
<a href="#an-example-using-mclust" class="anchor"></a>4. An example using mclust</h2>
<p>Here is a very short example using the built-in data set <code>pisaUSA15</code>.</p>
<p>Note that outliers may wish to be removed first; consider identifying both univariate and multivariate outliers.</p>
<p>First, you can install the package from CRAN as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/install.packages">install.packages</a></span>(<span class="st">"tidyLPA"</span>)</code></pre></div>
<p>You can also install the in-development version of tidyLPA from GitHub with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/install.packages">install.packages</a></span>(<span class="st">"devtools"</span>)
devtools<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/devtools/topics/reexports">install_github</a></span>(<span class="st">"jrosen48/tidyLPA"</span>)</code></pre></div>
<p>Here is the simple example, using just a subset of the built-in <code>pisaUSA15</code> data, data from the 2015 PISA assessment (more details on the data set can be found <a href="https://github.com/jrosen48/pisaUSA15">here</a>). We load tidyLPA and create a subset of the <code>pisaUSA15</code> data for this example.</p>
<p>We use variables from the PISA assessment for United States students’ broad interest, enjoyment, and self_efficacy (each which is a composite of other measured, self-report variables).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(tidyLPA)
<span class="co">#&gt; Note that an update to tidyLPA is forthcoming; see vignette('introduction-to-major-changes') for details!</span>
d &lt;-<span class="st"> </span>pisaUSA15[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, ]</code></pre></div>
<p>Note that you may wish to identify (and remove) univariate and multivariate outliers. See the functions <a href="https://gist.github.com/jrosen48/094eee8627be43b167c7c79388027174">here</a> for some exampels.</p>
<p><strong>Comparing profile solutions</strong></p>
<p>Next, we use the <code><a href="../reference/compare_solutions.html">compare_solutions()</a></code> function to explore different solutions in terms of information criteria, specifically the Bayesian Information Criteria (BIC) (the ICL is also available, as others will be in future versions; add the argument <code>statistic = "ICL"</code> to plot the ICL values instead of the BIC values). The BIC is based on the log-likelihood value for the model, but it accounts for the complexity of the model in terms of its degrees of freedom, penalizing more complex models with higher BICs. The goal of this step is to determine whether certain models and certain numbers of profiles are associated with lower BIC values, which then suggest further, detailed analysis in the next step.</p>
<p>To use the function, we provide the name of the <code>data.frame</code>, <code>d</code>, first, followed by the names of the variables to be used to create the profiles next, separated by commas. This syntax is familiar to those who have used functions such as <code><a href="http://dplyr.tidyverse.org/reference/select.html">select()</a></code> from the <a href="http://dplyr.tidyverse.org/">dplyr</a> package (and other <a href="http://tidyverse.org/">“tidyverse”</a> packages).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/compare_solutions.html">compare_solutions</a></span>(d, broad_interest, enjoyment, self_efficacy)</code></pre></div>
<p><img src="Introduction_to_tidyLPA_files/figure-html/unnamed-chunk-4-1.png" width="700"></p>
<p>While these BIC values are ambiguous for this data, consider that one solution exhibited the best fit and the analyst was interested in interrogating it further.</p>
<p>To do this, we use the <code><a href="../reference/estimate_profiles.html">estimate_profiles()</a></code> function.</p>
<p><strong>Estimating parameters of profiles for a specific solution</strong></p>
<p>Here, we are estimating the parameters (depending on the model specified, means, variances, and covariances) that characterize the profiles. Like the <code><a href="../reference/compare_solutions.html">compare_solutions()</a></code>, the first argument to <code><a href="../reference/estimate_profiles.html">estimate_profiles()</a></code> is the <code>data.frame</code>, <code>d</code>, followed by the names of the variables to be used to create the profiles separated by commas.</p>
<p>When we run the following line, we see a number of statistics - <code>LogLik</code> for the log-likelihood, information criteria, as well as the entropy. For the log-likelihood and information criteria statistics, lower values are generally indicative of a preferred solution; for the entropy statistic, higher values are generally indicative of a preferred solution. <a href="https://www.sciencedirect.com/science/article/pii/S0361476X06000543">Pastor, Barron, Miller, and Davis (2007)</a> provide an accessible introduction to interpreting these values.</p>
<p>Note that these statistics are printed as messages by default but can be suppressed by adding the argument <code>print_which_stats = "none"</code> to <code><a href="../reference/estimate_profiles.html">estimate_profiles()</a></code>; additional fit statistics can be returned by adding the <code>print_which_stats = "all"</code> as the argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                        broad_interest, enjoyment, self_efficacy,
                        <span class="dt">n_profiles =</span> <span class="dv">4</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 4 profiles.</span>
<span class="co">#&gt; LogLik is 271.511</span>
<span class="co">#&gt; BIC is 624.802</span>
<span class="co">#&gt; Entropy is 0.952</span></code></pre></div>
<p>We fit the model and saved the output to the object <code>m3</code>. Next, we may want to examine the output in terms of the estimated means and variances of the variables for each of the profiles. We can do this with the <code><a href="../reference/plot_profiles.html">plot_profiles()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/plot_profiles.html">plot_profiles</a></span>(m3)</code></pre></div>
<p><img src="Introduction_to_tidyLPA_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
<p>We can also center or standardize the variables (to have grand mean equal to 0 and standard deviation equal t 1, respectively), with the <code>to_center</code> and <code>to_scale</code> arguments to <code><a href="../reference/plot_profiles.html">plot_profiles()</a></code>, i.e.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/plot_profiles.html">plot_profiles</a></span>(m3, <span class="dt">to_center =</span> <span class="ot">TRUE</span>, <span class="dt">to_scale =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p><img src="Introduction_to_tidyLPA_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<p>A different, identical way to do the above is to use the “pipe” operator (<code>%&gt;%</code>)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(dplyr, <span class="dt">warn.conflicts =</span> <span class="ot">FALSE</span>)

<span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                  broad_interest, enjoyment, self_efficacy, 
                  <span class="dt">n_profiles =</span> <span class="dv">3</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../reference/plot_profiles.html">plot_profiles</a></span>(<span class="dt">to_center =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 3 profiles.</span>
<span class="co">#&gt; LogLik is 283.991</span>
<span class="co">#&gt; BIC is 631.589</span>
<span class="co">#&gt; Entropy is 0.914</span></code></pre></div>
<p><img src="Introduction_to_tidyLPA_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
<p>Finally, we can use the output from <strong>mclust</strong> directly by using adding <code>to_return = "mclust"</code> to the <code><a href="../reference/estimate_profiles.html">estimate_profiles()</a></code> function, plotting the (bootstrapped) standard errors (and, by default–but optionally–the raw data), rather than from the posterior classifications of the observations, as in the plots not using the <strong>mclust</strong> output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                        broad_interest, enjoyment, self_efficacy, 
                        <span class="dt">n_profiles =</span> <span class="dv">3</span>, <span class="dt">to_return =</span> <span class="st">"mclust"</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 3 profiles.</span>
<span class="co">#&gt; LogLik is 283.991</span>
<span class="co">#&gt; BIC is 631.589</span>
<span class="co">#&gt; Entropy is 0.914</span>

<span class="kw"><a href="../reference/plot_profiles.html">plot_profiles</a></span>(m3, <span class="dt">plot_what =</span> <span class="st">"mclust"</span>)
<span class="co">#&gt; Warning in plot_profiles(m3, plot_what = "mclust"): The number of cases per</span>
<span class="co">#&gt; class is relatively low in some classes. Used weighted likelihood bootstrap</span>
<span class="co">#&gt; to obtain se's.</span></code></pre></div>
<p><img src="Introduction_to_tidyLPA_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
<div id="more-information-on-model-specifications" class="section level1">
<h1 class="hasAnchor">
<a href="#more-information-on-model-specifications" class="anchor"></a>5. More information on model specifications</h1>
<p>As mentioned earlier, there are a number of different models representing how - or whether - different parameters are estimated. These are passed to the <code>variance</code> and <code>covariance</code> arguments. The possible values for these arguments are:</p>
<ul>
<li>
<code>variances</code>: “equal” and “zero”</li>
<li>
<code>covariances</code>: “varying”, “equal”, and “zero”</li>
</ul>
<p>Here is an example of specifying a model with varying variances and covariances:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                  broad_interest, enjoyment, self_efficacy, 
                  <span class="dt">variances =</span> <span class="st">"varying"</span>,
                  <span class="dt">covariances =</span> <span class="st">"varying"</span>,
                  <span class="dt">n_profiles =</span> <span class="dv">3</span>)
<span class="co">#&gt; Fit NA model with 3 profiles.</span>
<span class="co">#&gt; LogLik is 262.567</span>
<span class="co">#&gt; BIC is 656.889</span>
<span class="co">#&gt; Entropy is 0.953</span>
<span class="co">#&gt; # A tibble: 94 x 5</span>
<span class="co">#&gt;    broad_interest enjoyment self_efficacy profile posterior_prob</span>
<span class="co">#&gt;             &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;            &lt;dbl&gt;</span>
<span class="co">#&gt;  1            3.8       4            1    1                1.000</span>
<span class="co">#&gt;  2            3         3            2.75 2                0.982</span>
<span class="co">#&gt;  3            1.8       2.8          3.38 2                1    </span>
<span class="co">#&gt;  4            1.4       1            2.75 2                0.996</span>
<span class="co">#&gt;  5            1.8       2.2          2    3                0.981</span>
<span class="co">#&gt;  6            1.6       1.6          1.88 3                0.994</span>
<span class="co">#&gt;  7            3         3.8          2.25 3                0.915</span>
<span class="co">#&gt;  8            2.6       2.2          2    3                0.978</span>
<span class="co">#&gt;  9            1         2.8          2.62 2                0.786</span>
<span class="co">#&gt; 10            2.2       2            1.75 3                0.996</span>
<span class="co">#&gt; # ... with 84 more rows</span></code></pre></div>
<p>In general, the approach to choosing the model is similar to choosing the number of profiles, requiring <strong>deciding on the basis of evidence from multiple sources</strong>, including information criteria, statistical tests, and concerns of interpretability and parsimony. The article by <a href="http://www.sciencedirect.com/science/article/pii/S0361476X06000543">Pastor and colleagues (2007)</a> has helpful information on the model specifications. Here, the six models that are possible to specify in LPA are described in terms of how the variables used to create the profiles are estimated.</p>
<p>Note that <em>p</em> represents different profiles and each parameterization is represented by a 4 x 4 covariance matrix and therefore would represent the parameterization for a four-profile solution. In all of the models, the means are estimated freely in the different profiles. Imagine that each row and column represents a different variable, i.e., the first row (and column) represents broad interest, the second enjoyment, the third self-efficacy, and the fourth another variable, i.e., future goals and plans.</p>
<div id="equal-variances-and-covariances-fixed-to-0-model-1" class="section level4">
<h4 class="hasAnchor">
<a href="#equal-variances-and-covariances-fixed-to-0-model-1" class="anchor"></a>1. Equal variances, and covariances fixed to 0 (model 1)</h4>
<p>In this model, which corresponds to the mclust model wit the name “EEI”, the variances are estimated to be equal across profiles, indicated by the absence of a p subscript for any of the diagonal elements of the matrix. The covariances are constrained to be zero, as indicated by the 0’s between every combination of the variables.</p>
<p>It is specified with <code>variances = "equal"</code> and <code>covariances = "zero"</code>.</p>
<p>This model is highly constrained but also parsimonious: the profiles are estimated in such a way that the variables’ variances are identical for each of the profiles, and the relationships between the variables are not estimated. In this way, less degrees of freedom are taken used to explain the observations that make up the data. However, estimating more parameters–as in the other models–may better explain the data, justifying the addition in complexity that their addition involves (and their reduction in degrees of freedom). This model is sometimes referred to as a <em>class-invariant</em> parameterization.</p>
<p><span class="math display">\[
\left[ \begin{matrix} { \sigma  }_{ 1 }^{ 2 } &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; { \sigma  }_{ 2 }^{ 2 } &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; { \sigma  }_{ 3 }^{ 2 } &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; { \sigma  }_{ 4 }^{ 2 } \end{matrix} \right] 
\]</span></p>
</div>
<div id="varying-variances-and-covariances-fixed-to-0-model-2" class="section level4">
<h4 class="hasAnchor">
<a href="#varying-variances-and-covariances-fixed-to-0-model-2" class="anchor"></a>2. Varying variances and covariances fixed to 0 (model 2)</h4>
<p>This model corresponds to the mclust model “VVI” and allows for the variances to be freely estimated across profiles. The covariances are constrained to zero.</p>
<p>It is specified with <code>variances = "varying"</code> and <code>covariances = "zero"</code>.</p>
<p>Thus, it is more flexible (and less parsimonious) than model 1, but in terms of the covariances, is more constrained than model 2. This model is sometimes referred to as a <em>class-varying diagonal</em> parameterization.</p>
<p><span class="math display">\[ 
\left[ \begin{matrix} { \sigma  }_{ 1p }^{ 2 } &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; { \sigma  }_{ 2p }^{ 2 } &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; { \sigma  }_{ 3p }^{ 2 } &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; { \sigma  }_{ 4p }^{ 2 } \end{matrix} \right] 
\]</span></p>
</div>
<div id="equal-variances-and-equal-covariances-model-3" class="section level4">
<h4 class="hasAnchor">
<a href="#equal-variances-and-equal-covariances-model-3" class="anchor"></a>3. Equal variances and equal covariances (model 3)</h4>
<p>This model corresponds to the mclust model “EEE”. In this model, the variances are still constrained to be the same across the profiles, although now the covariances are estimated (but like the variances, are constrained to be the same across profiles).</p>
<p>It is specified with <code>variances = "equal"</code> and <code>covariances = "equal"</code>.</p>
<p>Thus, this model is the first to estimate the covariance (or correlations) of the variables used to create the profiles, thus adding more information that can be used to better understand the characteristics of the profiles (and, potentially, better explain the data). This model is sometimes referred to as a <em>class-invariant unrestricted</em> parameterization.</p>
<p><span class="math display">\[
\left[ \begin{matrix} { \sigma  }_{ 1 }^{ 2 } &amp; { \sigma  }_{ 21 } &amp; { \sigma  }_{ 31 } &amp; { \sigma  }_{ 41 } \\ { \sigma  }_{ 12 } &amp; { \sigma  }_{ 2 }^{ 2 } &amp; { \sigma  }_{ 23 } &amp; { \sigma  }_{ 24 } \\ { \sigma  }_{ 13 } &amp; { \sigma  }_{ 12 } &amp; { \sigma  }_{ 3 }^{ 2 } &amp; { \sigma  }_{ 33 } \\ { \sigma  }_{ 14 } &amp; { \sigma  }_{ 12 } &amp; { \sigma  }_{ 12 } &amp; { \sigma  }_{ 4 }^{ 2 } \end{matrix} \right] 
\]</span></p>
</div>
<div id="varying-means-varying-variances-and-equal-covariances-model-4" class="section level4">
<h4 class="hasAnchor">
<a href="#varying-means-varying-variances-and-equal-covariances-model-4" class="anchor"></a>4. Varying means, varying variances, and equal covariances (model 4)</h4>
<p>This model, which specifies for the variances to be freely estimated across the profiles and for the covariances to be estimated to be equal across profiles, extends model 3.</p>
<p>It is specified with <code>variances = "varying"</code> and <code>covariances = "equal"</code>.</p>
<p>Unfortunately, this model cannot be specified with mclust, though it can be with MPlus; this model <em>can</em> be used with the functions to interface to MPlus described below.</p>
<p><span class="math display">\[
\left[ \begin{matrix} { \sigma  }_{ 1p }^{ 2 } &amp; { \sigma  }_{ 21 } &amp; { \sigma  }_{ 31 } &amp; { \sigma  }_{ 41 } \\ { \sigma  }_{ 12 } &amp; { \sigma  }_{ 2p }^{ 2 } &amp; { \sigma  }_{ 23 } &amp; { \sigma  }_{ 24 } \\ { \sigma  }_{ 13 } &amp; { \sigma  }_{ 12 } &amp; { \sigma  }_{ 3p }^{ 2 } &amp; { \sigma  }_{ 33 } \\ { \sigma  }_{ 14 } &amp; { \sigma  }_{ 12 } &amp; { \sigma  }_{ 12 } &amp; { \sigma  }_{ 4p }^{ 2 } \end{matrix} \right] 
\]</span></p>
</div>
<div id="varying-means-equal-variances-and-varying-covariances-model-5" class="section level4">
<h4 class="hasAnchor">
<a href="#varying-means-equal-variances-and-varying-covariances-model-5" class="anchor"></a>5. Varying means, equal variances, and varying covariances (model 5)</h4>
<p>This model specifies the variances to be equal across the profiles, but allows the covariances to be freely estimated across the profiles.</p>
<p>It is specified with <code>variances = "equal"</code> and <code>covariances = "varying"</code>.</p>
<p>Like model 4, this model cannot be specified with mclust, though it can be with MPlus. Again, this model <em>can</em> be used with the functions to interface to MPlus described below.</p>
<p><span class="math display">\[
\left[ \begin{matrix} { \sigma  }_{ 1 }^{ 2 } &amp; { \sigma  }_{ 21p } &amp; { \sigma  }_{ 31p } &amp; { \sigma  }_{ 41p } \\ { \sigma  }_{ 12p } &amp; { \sigma  }_{ 2 }^{ 2 } &amp; { \sigma  }_{ 23p } &amp; { \sigma  }_{ 24p } \\ { \sigma  }_{ 13p } &amp; { \sigma  }_{ 12p } &amp; { \sigma  }_{ 3 }^{ 2 } &amp; { \sigma  }_{ 33p } \\ { \sigma  }_{ 14p } &amp; { \sigma  }_{ 12p } &amp; { \sigma  }_{ 12p } &amp; { \sigma  }_{ 4 }^{ 2 } \end{matrix} \right] \quad 
\]</span></p>
</div>
<div id="varying-variances-and-varying-covariances-model-4" class="section level4">
<h4 class="hasAnchor">
<a href="#varying-variances-and-varying-covariances-model-4" class="anchor"></a>6. Varying variances and varying covariances (model 4)</h4>
<p>This model corresponds to the mclust model “VVV”. It allows the variances and the covariances to be freely estimated across profiles.</p>
<p>It is specified with <code>variances = "varying"</code> and <code>covariances = "varying"</code>.</p>
<p>Thus, it is the most complex model, with the potential to allow for understanding many aspects of the variables that are used to estimate the profiles and how they are related. However, it is less parsimonious than all of the other models, and the added parameters should be considered in light of how preferred this model is relative to those with more simple specifications. This model is sometimes referred to as a <em>class-varying unrestricted</em> parameterization.</p>
<p><span class="math display">\[
\left[ \begin{matrix} { \sigma  }_{ 1p }^{ 2 } &amp; { \sigma  }_{ 21p } &amp; { \sigma  }_{ 31p } &amp; { \sigma  }_{ 41p } \\ { \sigma  }_{ 12p } &amp; { \sigma  }_{ 2p }^{ 2 } &amp; { \sigma  }_{ 23p } &amp; { \sigma  }_{ 24p } \\ { \sigma  }_{ 13p } &amp; { \sigma  }_{ 12p } &amp; { \sigma  }_{ 3p }^{ 2 } &amp; { \sigma  }_{ 33p } \\ { \sigma  }_{ 14p } &amp; { \sigma  }_{ 12p } &amp; { \sigma  }_{ 12p } &amp; { \sigma  }_{ 4p }^{ 2 } \end{matrix} \right] 
\]</span></p>
</div>
<div id="other-options" class="section level2">
<h2 class="hasAnchor">
<a href="#other-options" class="anchor"></a>6. Other options</h2>
<p>There is a lot of output that is possible to obtain from the <code><a href="../reference/estimate_profiles.html">estimate_profiles()</a></code> function - much more than a tidy data frame, which is the default. The easiest way to access it is by changing what is returned; by default, the function returns a <code>data.frame</code> (more precisely, a <code>tibble</code>) with the variables used to create the profiles and the profile with the highest posterior probability (and the posterior probability for the profile):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d,
                  broad_interest, enjoyment, self_efficacy,
                  <span class="dt">n_profiles =</span> <span class="dv">4</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 4 profiles.</span>
<span class="co">#&gt; LogLik is 271.511</span>
<span class="co">#&gt; BIC is 624.802</span>
<span class="co">#&gt; Entropy is 0.952</span>
<span class="co">#&gt; # A tibble: 94 x 5</span>
<span class="co">#&gt;    broad_interest enjoyment self_efficacy profile posterior_prob</span>
<span class="co">#&gt;             &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;            &lt;dbl&gt;</span>
<span class="co">#&gt;  1            3.8       4            1    1                1    </span>
<span class="co">#&gt;  2            3         3            2.75 4                1.000</span>
<span class="co">#&gt;  3            1.8       2.8          3.38 4                0.965</span>
<span class="co">#&gt;  4            1.4       1            2.75 2                1.000</span>
<span class="co">#&gt;  5            1.8       2.2          2    3                0.996</span>
<span class="co">#&gt;  6            1.6       1.6          1.88 3                0.963</span>
<span class="co">#&gt;  7            3         3.8          2.25 1                0.996</span>
<span class="co">#&gt;  8            2.6       2.2          2    3                0.986</span>
<span class="co">#&gt;  9            1         2.8          2.62 4                0.908</span>
<span class="co">#&gt; 10            2.2       2            1.75 3                1.000</span>
<span class="co">#&gt; # ... with 84 more rows</span></code></pre></div>
<p>One way to access the additional output is to use the <code><a href="https://www.rdocumentation.org/packages/base/topics/attributes">attributes()</a></code> function on the output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/attributes">attributes</a></span>(m3)<span class="op">$</span>mclust_output<span class="op">$</span>parameters
<span class="co">#&gt; NULL</span></code></pre></div>
<p>Another way is to change the <code>to_return</code> argument to “mclust” to instead return the full output from the estimation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3_mclust &lt;-<span class="st"> </span><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                               broad_interest, enjoyment, self_efficacy, 
                               <span class="dt">n_profiles =</span> <span class="dv">4</span>, 
                               <span class="dt">to_return =</span> <span class="st">"mclust"</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 4 profiles.</span>
<span class="co">#&gt; LogLik is 271.511</span>
<span class="co">#&gt; BIC is 624.802</span>
<span class="co">#&gt; Entropy is 0.952</span></code></pre></div>
<p>This object can be inspected manually (see <code><a href="https://www.rdocumentation.org/packages/utils/topics/str">str(m3_clust)</a></code>) or through helper functions available in mclust, i.e.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3_mclust<span class="op">$</span>parameters
<span class="co">#&gt; $pro</span>
<span class="co">#&gt; [1] 0.20844740 0.04426354 0.31001984 0.43726922</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $mean</span>
<span class="co">#&gt;                    [,1]     [,2]     [,3]     [,4]</span>
<span class="co">#&gt; broad_interest 3.089074 1.435974 1.979601 2.712883</span>
<span class="co">#&gt; enjoyment      3.833430 1.071682 2.126969 2.933941</span>
<span class="co">#&gt; self_efficacy  1.500661 2.859656 2.224995 2.147173</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance</span>
<span class="co">#&gt; $variance$modelName</span>
<span class="co">#&gt; [1] "EEI"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance$d</span>
<span class="co">#&gt; [1] 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance$G</span>
<span class="co">#&gt; [1] 4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance$sigma</span>
<span class="co">#&gt; , , 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                broad_interest  enjoyment self_efficacy</span>
<span class="co">#&gt; broad_interest      0.4760132 0.00000000     0.0000000</span>
<span class="co">#&gt; enjoyment           0.0000000 0.05287357     0.0000000</span>
<span class="co">#&gt; self_efficacy       0.0000000 0.00000000     0.3022866</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                broad_interest  enjoyment self_efficacy</span>
<span class="co">#&gt; broad_interest      0.4760132 0.00000000     0.0000000</span>
<span class="co">#&gt; enjoyment           0.0000000 0.05287357     0.0000000</span>
<span class="co">#&gt; self_efficacy       0.0000000 0.00000000     0.3022866</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 3</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                broad_interest  enjoyment self_efficacy</span>
<span class="co">#&gt; broad_interest      0.4760132 0.00000000     0.0000000</span>
<span class="co">#&gt; enjoyment           0.0000000 0.05287357     0.0000000</span>
<span class="co">#&gt; self_efficacy       0.0000000 0.00000000     0.3022866</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; , , 4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                broad_interest  enjoyment self_efficacy</span>
<span class="co">#&gt; broad_interest      0.4760132 0.00000000     0.0000000</span>
<span class="co">#&gt; enjoyment           0.0000000 0.05287357     0.0000000</span>
<span class="co">#&gt; self_efficacy       0.0000000 0.00000000     0.3022866</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance$Sigma</span>
<span class="co">#&gt;                broad_interest  enjoyment self_efficacy</span>
<span class="co">#&gt; broad_interest      0.4760132 0.00000000     0.0000000</span>
<span class="co">#&gt; enjoyment           0.0000000 0.05287357     0.0000000</span>
<span class="co">#&gt; self_efficacy       0.0000000 0.00000000     0.3022866</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance$scale</span>
<span class="co">#&gt; [1] 0.1966794</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $variance$shape</span>
<span class="co">#&gt; [1] 2.4202495 0.2688313 1.5369512</span></code></pre></div>
<p>Other options include how the raw data is processed. We can center or scale the data before estimating the profiles with the <code>center_raw_data</code> and <code>scale_raw_data</code> functions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3_processed_raw &lt;-<span class="st"> </span><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                                      broad_interest, enjoyment, self_efficacy, 
                                      <span class="dt">n_profiles =</span> <span class="dv">4</span>, 
                                      <span class="dt">center_raw_data =</span> <span class="ot">TRUE</span>, 
                                      <span class="dt">scale_raw_data =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 4 profiles.</span>
<span class="co">#&gt; LogLik is 356.415</span>
<span class="co">#&gt; BIC is 794.609</span>
<span class="co">#&gt; Entropy is 0.951</span></code></pre></div>
<p>Since we often wish to use the estimated profiles in subsequent analyses, we may want the original <code>data.frame</code>, with variables that are predictors or outcomes of the profiles, included. Here, we created profiles with just two of the three variables, to demonstrate how the third variable is still returned in the output. We can return this <code>data.frame</code>, and not just one with the variables used to create the profiles and the profile assignments (and posterior probabilities), using the argument <code>return_orig_df</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d, 
                  broad_interest, enjoyment,
                  <span class="dt">n_profiles =</span> <span class="dv">4</span>, 
                  <span class="dt">return_orig_df =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Fit Equal variances and covariances fixed to 0 (model 1) model with 4 profiles.</span>
<span class="co">#&gt; LogLik is 204.658</span>
<span class="co">#&gt; BIC is 468.378</span>
<span class="co">#&gt; Entropy is 0.828</span>
<span class="co">#&gt; # A tibble: 94 x 6</span>
<span class="co">#&gt;    broad_interest enjoyment instrumental_mot self_efficacy profile</span>
<span class="co">#&gt;             &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;  </span>
<span class="co">#&gt;  1            3.8       4               2             1    1      </span>
<span class="co">#&gt;  2            3         3               2.5           2.75 2      </span>
<span class="co">#&gt;  3            1.8       2.8             3.5           3.38 2      </span>
<span class="co">#&gt;  4            1.4       1               2.75          2.75 4      </span>
<span class="co">#&gt;  5            1.8       2.2             2             2    4      </span>
<span class="co">#&gt;  6            1.6       1.6             2.75          1.88 4      </span>
<span class="co">#&gt;  7            3         3.8             1.25          2.25 1      </span>
<span class="co">#&gt;  8            2.6       2.2             2             2    2      </span>
<span class="co">#&gt;  9            1         2.8             1             2.62 4      </span>
<span class="co">#&gt; 10            2.2       2               1             1.75 4      </span>
<span class="co">#&gt; # ... with 84 more rows, and 1 more variable: posterior_prob &lt;dbl&gt;</span></code></pre></div>
<p>Future versions will include the option to use random starts; by default, mclust uses the results from hierarchical clustering as the starting points for the EM algorithm.</p>
</div>
<div id="an-interface-to-mplus-in-development" class="section level2">
<h2 class="hasAnchor">
<a href="#an-interface-to-mplus-in-development" class="anchor"></a>7. An interface to MPlus (in-development)</h2>
<p><code>tidyLPA</code> has been bench marked to MPlus, at least for a simple data set (the <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">iris dataset</a>) and with three of the more common model specifications. You can find the results of that bench marking, which showed the results to be (nearly) identical, <a href="https://jrosen48.github.io/blog/comparing-mplus-and-mclust-output/">here</a>.</p>
<p>There is an in-development function to generate the model syntax (and prepare the data) and run the same models through the Mplus software. <strong>Note that you must have purchased and installed MPlus for these functions to work</strong>. Note that these functions are still in-development; the MPlus model syntax is dynamically generated for each model specified and then run through MPlus using the <a href="https://cran.r-project.org/package=MplusAutomation">MplusAutomation package</a>. These can be helpful for comparing the results between mclust and MPlus and for using output of the MPlus analyses in subsequent analyses, which can be difficult when using MPlus in a stand-alone matter.</p>
<p>Here is how to compare a number of models using MPlus (it works very similarly to <code><a href="../reference/compare_solutions.html">compare_solutions()</a></code>). Note that this and subsequent code using MPlus is not run in the vignette.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/compare_solutions_mplus.html">compare_solutions_mplus</a></span>(d, broad_interest, enjoyment, self_efficacy)</code></pre></div>
<p>In order to see a number of fit statistics, you can add the argument <code>return_stats_df = TRUE</code>, i.e.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/compare_solutions_mplus.html">compare_solutions_mplus</a></span>(d, broad_interest, enjoyment, self_efficacy,
                        <span class="dt">return_stats_df =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>Note that there is an option to use multiple cores (processors) to speed these functions; you can use the <code><a href="https://www.rdocumentation.org/packages/parallel/topics/detectCores">detectCores()</a></code> function from the parallel package to determine how many processors you have:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span> (<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">require</a></span>(<span class="st">'parallel'</span>)) {
  parallel<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/parallel/topics/detectCores">detectCores</a></span>()
}
<span class="co">#&gt; Loading required package: parallel</span>
<span class="co">#&gt; [1] 8</span></code></pre></div>
<p>Then, you can set the <code>n_processors</code> argument (for all of the functions that use MPlus) to that number, i.e.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/compare_solutions_mplus.html">compare_solutions_mplus</a></span>(d, broad_interest, enjoyment, self_efficacy, <span class="dt">n_processors =</span> <span class="dv">4</span>)</code></pre></div>
<p>Here is how to estimate profiles for a single solution. This function is very similar to <code><a href="../reference/estimate_profiles.html">estimate_profiles()</a></code>. Note that in addition to returning the profile assignment (<code>C</code>), the profile with the highest posterior probability, it also returns the posterior probabilities for the other profiles:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/estimate_profiles_mplus.html">estimate_profiles_mplus</a></span>(d, 
                              broad_interest, enjoyment, self_efficacy, 
                              <span class="dt">n_profiles =</span> <span class="dv">3</span>)</code></pre></div>
<p>There are many options to control the estimation (i.e., changing the number of starts); see the help for this function (<code>?estimate_profiles_mplus()</code>) for information about the arguments that can be used.</p>
<p>We can plot the profile solution using <code><a href="../reference/plot_profiles_mplus.html">plot_profiles_mplus()</a></code>; the same arguments to center and scale the data can be used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/plot_profiles_mplus.html">plot_profiles_mplus</a></span>(m1, <span class="dt">to_center =</span> <span class="ot">TRUE</span>, <span class="dt">to_scale =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>These functions will be further developed in subsequent versions.</p>
</div>
<div id="other-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#other-functions" class="anchor"></a>8. Other functions</h2>
<p>There are a few other features of tidyLPA that will be described further in subsequent versions. Two that are available now that are briefly described are the use of a bootstrapped likelihood-ratio test and a prior. Both are presently only available for the mclust functions (i.e., it is not yet available through tidyLPA for the functions that use MPlus)</p>
<p><strong>Bootstrapped likelihood-ratio test (LRT)</strong></p>
<p>To determine the number of profiles for a specified model (i.e., models <code>1</code>-<code>4</code> described above, we can carry out a bootstrapped likelihood-ratio test. Note that the code is shown but run because it can take substantial time, even for a small data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/bootstrap_lrt.html">bootstrap_lrt</a></span>(d, broad_interest, enjoyment, self_efficacy)</code></pre></div>
<p><strong>Use of a prior</strong></p>
<p>Models fit with mclust can be estimated with a prior. This can be helpful for estimating models that might otherwise not be able to be estimated. Learn more in Fraley and Raftery (2007) <a href="https://link.springer.com/article/10.1007%2Fs00357-007-0004-5?LI=true">here</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/estimate_profiles.html">estimate_profiles</a></span>(d,
                  broad_interest, enjoyment, self_efficacy, 
                  <span class="dt">n_profiles =</span> <span class="dv">4</span>,
                  <span class="dt">prior_control =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="conclusion" class="section level2">
<h2 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>9. Conclusion</h2>
<p>tidyLPA is actively being developed and this vignette will change as the package continues to be developed and used. The latest version of tidyLPA is available <a href="https://github.com/jrosen48/tidyLPA">here</a> on GitHub. More information is also available on the tidyLPA website <a href="https://jrosen48.github.io/tidyLPA/">here</a></p>
<p><strong>Notes</strong></p>
<p>This is related to <a href="https://github.com/jrosen48/prcr">prcr</a>, for use of two-step cluster analysis to carry out person-oriented analyses.</p>
<p>To contribute, file issues via GitHub <a href="https://github.com/jrosen48/tidyLPA/issues">here</a> or get in touch <a href="mailto:jrosen@msu.edu">via email</a> or <a href="https://twitter.com/jrosenberg6432">Twitter</a>.</p>
<p><strong>References</strong></p>
<p>Pastor, D. A., Barron, K. E., Miller, B. J., &amp; Davis, S. L. (2007). A latent profile analysis of college students’ achievement goal orientation. <em>Contemporary Educational Psychology, 32</em>(1), 8-47. (<a href="https://www.sciencedirect.com/science/article/pii/S0361476X06000543" class="uri">https://www.sciencedirect.com/science/article/pii/S0361476X06000543</a></p>
<p><strong>Helpful resources</strong></p>
<ul>
<li><p><a href="https://www.amazon.com/Handbook-Cluster-Analysis-Handbooks-Statistical/dp/1466551887/ref=sr_1_1?ie=UTF8&amp;qid=1517773186&amp;sr=8-1&amp;keywords=cluster+analysis+handbook">Hennig et al’s (2015)</a> handbook for an overview of mixture models, of which LPA is often considered an instance of.</p></li>
<li><p><a href="https://books.Google.com/books?hl=en&amp;lr=&amp;id=gPJQWKsgh3YC&amp;oi=fnd&amp;pg=PT12&amp;dq=collins+lanza&amp;ots=_0L9qnxxun&amp;sig=Vx9RhJgIv0zbttIgvYLxaUQwtFI#v=onepage&amp;q=collins%20lanza&amp;f=false">Collins and Lanza (2013)</a> for a book on the related approach (for use with dichotomous, rather than continuous variables used to create the profiles) Latent Class Analysis (LCA)</p></li>
</ul>
<p><strong>How to cite tidyLPA</strong></p>
<blockquote>
<p>Rosenberg, J. M., Beymer, P. N., Anderson, D. J., &amp; Schmidt, J. A. (2018). tidyLPA: An R Package to Easily Carry Out Latent Profile Analysis (LPA) Using Open-Source or Commercial Software. <em>Journal of Open Source Software, 3</em>(30), 978, <a href="https://doi.org/10.21105/joss.00978" class="uri">https://doi.org/10.21105/joss.00978</a></p>
</blockquote>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#background-on-latent-profile-analysis-lpa">1. Background on Latent Profile Analysis (LPA)</a></li>
      <li><a href="#description-of-the-goals-of-tidylpa">2. Description of the goals of tidyLPA</a></li>
      <li><a href="#software-approach-to-carrying-out-lpa-interface-to-mclust-and-to-mplus">3. Software approach to carrying out LPA: Interface to mclust (and to MPlus)</a></li>
      <li><a href="#an-example-using-mclust">4. An example using mclust</a></li>
      <li>
<a href="#more-information-on-model-specifications">5. More information on model specifications</a><ul class="nav nav-pills nav-stacked">
<li><a href="#other-options">6. Other options</a></li>
      <li><a href="#an-interface-to-mplus-in-development">7. An interface to MPlus (in-development)</a></li>
      <li><a href="#other-functions">8. Other functions</a></li>
      <li><a href="#conclusion">9. Conclusion</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Joshua M Rosenberg, Caspar van Lissa.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
